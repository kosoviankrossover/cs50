text.lm
texts.lm
###########################
# Stat 111, Problem Set 8 #
###########################
# Instructions:
# Upload to Canvas as your_name.R, replacing your_name with your actual name
# IMPORTANT:
# Note that you should be able to run your code all the way through.
# 1) Run this command to erase all variables you've defined:
#       rm(list = ls())
# 2) Paste all your code into R and run it without any errors
my_name = "Meriton Ibrahimi"
#### Read Data ####
gssconvicted <- read.csv("http://stat111.github.io/gssconvicted.csv", header = T)
texts.dat <- read.csv("http://stat111.github.io/stat111textshw8.csv", header = T)
#### Problem 2 ####
# You can use functions from your old psets here
logistic.loglik = function(par, y, x){
a = (par[1]) + ((par[2])*x)
value = sum( (y*a) -log(1 + exp(a)))
return(value)
}
logistic.score = function(par, y, x){
a = (par[1]) + ((par[2])*x)
value_b0 = sum(y - ((exp(a))/(1+exp(a))) )
value_b1 = sum( (y*x) - ( (x*(exp(a))) / (1 + exp(a)) ) )
return(c(value_b0, value_b1))
}
logistic.fisher = function(par, y, x){
a = (par[1]) + ((par[2])*x)
i11 = sum ( (exp(a)) / ((1 + exp(a))^2) )
i21 = sum ( (x*(exp(a))) / ((1 + exp(a))^2) )
i12 = i21
i22 = sum ( ((x^2)*(exp(a))) / ((1 + exp(a))^2) )
return(matrix(c(i11,i21,i12,i22), nrow=2, ncol=2))
}
### 2a
# Store the result of optim() here
beta.optim = optim(par= c(0,0), fn= logistic.loglik, control= list(fnscale=-1), y=gssconvicted$convicted, x=gssconvicted$foreignborn)
# Store the parameter estimates from optim() here
beta.mle = beta.optim$par
### 2b.
# The estimated probability that a foreign-born individual had a conviction
foreign = 1
p.convict.foreign = (exp(beta.mle[1] + ((beta.mle[2])*foreign))) / (1 + exp(beta.mle[1] + ((beta.mle[2])*foreign)))
# The estimated probability that a US-born individual had a conviction
usborn = 0
p.convict.us = (exp(beta.mle[1] + ((beta.mle[2])*usborn))) / (1 + exp(beta.mle[1] + ((beta.mle[2])*usborn)))
### 2c
# The Wald statistic for testing whether the probability of being convicted of a crime is the same for the 2 groups
var = solve(logistic.fisher(beta.mle, gssconvicted$convicted, gssconvicted$foreignborn))[2,2]
wstat = beta.mle[2]  * solve(var) * beta.mle[2]
wald.stat = wstat[1,1]
# The p-value for that Wald statistic
wald.pval = 1-pchisq(wald.stat, df=1)
### 2d
# If you attempt the extra credit, store the confidence interval here.
delta.method.ci = (p.convict.us - p.convict.foreign) + qnorm(c(.025, .975)) * sqrt(var)
#### Problem 3 ####
### 3c
splitconvicted = split(gssconvicted, gssconvicted$foreignborn)
foreigners = splitconvicted$`1`$convicted
borninus = splitconvicted$`0`$convicted
# The estimated proportion of US-born individuals who have been convicted of a crime
p1.hat = mean(borninus)
# The estimated proportion of foreign-born individuals who have been convicted of a crime
p2.hat = mean(foreigners)
### 3d
# The estimated difference (p1 - p2)
d.hat = p1.hat-p2.hat
# The test statistic for testing H0: D = 0
n1 = length(borninus)
n2 = length(foreigners)
p1.hat.var = (p1.hat*(1-p1.hat))/n1
p2.hat.var = (p2.hat*(1-p2.hat))/n2
test.stat.3d = d.hat/sqrt(p1.hat.var+p2.hat.var)
# The p-value for that test
p.val.3d = 2*(1-pnorm(test.stat.3d))
#### Problem 4 ####
### 4b
# The joint probability of observing all the data under model 1
# This should be an exact (not proportional) probability.
p1.function = function(p1){
return(choose(1521,204)*(p1^204)*((1-p1)^1317))
}
p2.function = function(p2){
return(choose(217,5)*(p2^5)*((1-p2)^212))
}
integrate.p1 = integrate(p1.function, 0, 1)
integrate.p2 = integrate(p2.function, 0, 1)
p.data.model1 = integrate.p1$value*integrate.p2$value
### 4c
# The joint probability of observing all the data under model 2
# This should be an exact (not proportional) probability.
p.function = function(p){
return(choose(1521,204)*choose(217,5)*((p^209)*((1-p)^1529)))
}
integrate.p = integrate(p.function, 0,1)
p.data.model2 = integrate.p$value
### 4c
# The Bayes factor that compares model 1 to model 2
bayes.factor = p.data.model1/p.data.model2
### 4f
p1hat = 204/1521
p2hat = 5/217
logm1 = log(p1.function(p1hat)*p2.function(p2hat))
phat = 209/1738
logm2 = log(p.function(phat))
# The BIC value for model 1
bic.model1 = (-2*logm1) + 2*(log(1738)+log(2*pi))
# The BIC value for model 2
bic.model2 = (-2*logm2) + 1*(log(1738)+log(2*pi))
#### Problem 5 ####
### 5a
# Summary statistics for the 'texts' variable
splittexts= split(texts.dat, texts.dat$female)
women = splittexts$`1`$texts
men = splittexts$`0`$texts
logwomen = log(women)
logmen = log(men)
texts.mean.women = mean(logwomen)
texts.n.women = length(logwomen)
texts.var.women = var(logwomen)
texts.sd.women = sqrt(texts.var.women)
texts.mean.men = mean(logmen)
texts.n.men = length(logmen)
texts.var.men = var(logmen)
texts.sd.men = sqrt(texts.var.men)
### 5b
# The test statistic for testing whether the variance of ln(texts) is the same for men as it is for women
test.stat.5b = texts.var.men / texts.var.women
# The p-value from that test
p.val.5b = 2*(1-pf(test.stat.5b, df1 = texts.n.men - 1, df2 = texts.n.women - 1))
### 5c
# The t-statistic for whether men and women send a different mean of ln(texts).
t.stat.5c = (texts.mean.men-texts.mean.women) / sqrt((texts.var.men/texts.n.men) + (texts.var.women/texts.n.women))
# The p-value for that test
# us the smaller of the sample sizes (lecture)
p.val.5c = 2*pt(t.stat.5c, df = texts.n.women-1)
### 5d
# Output from the t.test command forwhether men and women send a different mean of ln(texts).
t.test.5d = t.test(logwomen, logmen, paired = FALSE, alternative = "two.sided", conf.level = 0.95)
### 5e
# Output from a linear model that predicts 'ln(texts)' using 'female'
texts.lm = lm(log(texts.dat$texts) ~ texts.dat$female)
texts.lm
summary(texts.lm)
t.test.5d
pooledvar = (((texts.n.men - 1) * texts.var.men) + ((texts.n.women - 1) * texts.var.women)) / (texts.n.men + texts.n.women -2)
t.stat.5c = (texts.mean.men-texts.mean.women) / sqrt(pooledvar * ((1/texts.n.men)+(1/texts.n.women)))
t.stat.5c
p.val.5c = 2*pt(t.stat.5c, df = (text.n.men + texts.n.women-2))
p.val.5c = 2*pt(t.stat.5c, df = (texts.n.men + texts.n.women-2))
p.val.5c
test.stat.3d
phat = mean(gssconvicted$convicted)
phat
p.hat.var = phat*(1-phat)*((1/texts.n.men) + (1/text.n.women))
test.stat.3d = d.hat/sqrt(p.hat.var)
p1.hat.var = (p1.hat*(1-p1.hat))/n1
p2.hat.var = (p2.hat*(1-p2.hat))/n2
phat = mean(gssconvicted$convicted)
p.hat.var = phat*(1-phat)*((1/texts.n.men) + (1/texts.n.women))
test.stat.3d = d.hat/sqrt(p.hat.var)
test.stat.3d
phat
phat = mean(gssconvicted$convicted)
p.hat.var = phat*(1-phat)*((1/texts.n.men) + (1/texts.n.women))
test.stat.3d = d.hat/sqrt(p.hat.var)
test.stat.3d
phat
d.hat
p.hat.var
texts.n.men
texts.n.women
p.hat.var = phat*(1-phat)*((1/1521) + (1/217))
test.stat.3d = d.hat/sqrt(p.hat.var)
test.stat.3d
p.hat.var = phat*(1-phat)*((1/1521) + (1/217))
test.stat.3d = d.hat/sqrt(p.hat.var)
# The p-value for that test
p.val.3d = 2*(1-pnorm(test.stat.3d))
p.val.3d
###########################
# Stat 111, Problem Set 8 #
###########################
# Instructions:
# Upload to Canvas as your_name.R, replacing your_name with your actual name
# IMPORTANT:
# Note that you should be able to run your code all the way through.
# 1) Run this command to erase all variables you've defined:
#       rm(list = ls())
# 2) Paste all your code into R and run it without any errors
my_name = "Meriton Ibrahimi"
#### Read Data ####
gssconvicted <- read.csv("http://stat111.github.io/gssconvicted.csv", header = T)
texts.dat <- read.csv("http://stat111.github.io/stat111textshw8.csv", header = T)
#### Problem 2 ####
# You can use functions from your old psets here
logistic.loglik = function(par, y, x){
a = (par[1]) + ((par[2])*x)
value = sum( (y*a) -log(1 + exp(a)))
return(value)
}
logistic.score = function(par, y, x){
a = (par[1]) + ((par[2])*x)
value_b0 = sum(y - ((exp(a))/(1+exp(a))) )
value_b1 = sum( (y*x) - ( (x*(exp(a))) / (1 + exp(a)) ) )
return(c(value_b0, value_b1))
}
logistic.fisher = function(par, y, x){
a = (par[1]) + ((par[2])*x)
i11 = sum ( (exp(a)) / ((1 + exp(a))^2) )
i21 = sum ( (x*(exp(a))) / ((1 + exp(a))^2) )
i12 = i21
i22 = sum ( ((x^2)*(exp(a))) / ((1 + exp(a))^2) )
return(matrix(c(i11,i21,i12,i22), nrow=2, ncol=2))
}
### 2a
# Store the result of optim() here
beta.optim = optim(par= c(0,0), fn= logistic.loglik, control= list(fnscale=-1), y=gssconvicted$convicted, x=gssconvicted$foreignborn)
# Store the parameter estimates from optim() here
beta.mle = beta.optim$par
### 2b.
# The estimated probability that a foreign-born individual had a conviction
foreign = 1
p.convict.foreign = (exp(beta.mle[1] + ((beta.mle[2])*foreign))) / (1 + exp(beta.mle[1] + ((beta.mle[2])*foreign)))
# The estimated probability that a US-born individual had a conviction
usborn = 0
p.convict.us = (exp(beta.mle[1] + ((beta.mle[2])*usborn))) / (1 + exp(beta.mle[1] + ((beta.mle[2])*usborn)))
### 2c
# The Wald statistic for testing whether the probability of being convicted of a crime is the same for the 2 groups
var = solve(logistic.fisher(beta.mle, gssconvicted$convicted, gssconvicted$foreignborn))[2,2]
wstat = beta.mle[2]  * solve(var) * beta.mle[2]
wald.stat = wstat[1,1]
# The p-value for that Wald statistic
wald.pval = 1-pchisq(wald.stat, df=1)
### 2d
# If you attempt the extra credit, store the confidence interval here.
delta.method.ci = (p.convict.us - p.convict.foreign) + qnorm(c(.025, .975)) * sqrt(var)
#### Problem 3 ####
### 3c
splitconvicted = split(gssconvicted, gssconvicted$foreignborn)
foreigners = splitconvicted$`1`$convicted
borninus = splitconvicted$`0`$convicted
# The estimated proportion of US-born individuals who have been convicted of a crime
p1.hat = mean(borninus)
# The estimated proportion of foreign-born individuals who have been convicted of a crime
p2.hat = mean(foreigners)
### 3d
# The estimated difference (p1 - p2)
d.hat = p1.hat-p2.hat
# The test statistic for testing H0: D = 0
n1 = length(borninus)
n2 = length(foreigners)
p1.hat.var = (p1.hat*(1-p1.hat))/n1
p2.hat.var = (p2.hat*(1-p2.hat))/n2
phat = mean(gssconvicted$convicted)
p.hat.var = phat*(1-phat)*((1/1521) + (1/217))
test.stat.3d = d.hat/sqrt(p.hat.var)
# The p-value for that test
p.val.3d = 2*(1-pnorm(test.stat.3d))
#### Problem 4 ####
### 4b
# The joint probability of observing all the data under model 1
# This should be an exact (not proportional) probability.
p1.function = function(p1){
return(choose(1521,204)*(p1^204)*((1-p1)^1317))
}
p2.function = function(p2){
return(choose(217,5)*(p2^5)*((1-p2)^212))
}
integrate.p1 = integrate(p1.function, 0, 1)
integrate.p2 = integrate(p2.function, 0, 1)
p.data.model1 = integrate.p1$value*integrate.p2$value
### 4c
# The joint probability of observing all the data under model 2
# This should be an exact (not proportional) probability.
p.function = function(p){
return(choose(1521,204)*choose(217,5)*((p^209)*((1-p)^1529)))
}
integrate.p = integrate(p.function, 0,1)
p.data.model2 = integrate.p$value
### 4c
# The Bayes factor that compares model 1 to model 2
bayes.factor = p.data.model1/p.data.model2
### 4f
p1hat = 204/1521
p2hat = 5/217
logm1 = log(p1.function(p1hat)*p2.function(p2hat))
phat = 209/1738
logm2 = log(p.function(phat))
# The BIC value for model 1
bic.model1 = (-2*logm1) + 2*(log(1738)+log(2*pi))
# The BIC value for model 2
bic.model2 = (-2*logm2) + 1*(log(1738)+log(2*pi))
#### Problem 5 ####
### 5a
# Summary statistics for the 'texts' variable
splittexts= split(texts.dat, texts.dat$female)
women = splittexts$`1`$texts
men = splittexts$`0`$texts
logwomen = log(women)
logmen = log(men)
texts.mean.women = mean(logwomen)
texts.n.women = length(logwomen)
texts.var.women = var(logwomen)
texts.sd.women = sqrt(texts.var.women)
texts.mean.men = mean(logmen)
texts.n.men = length(logmen)
texts.var.men = var(logmen)
texts.sd.men = sqrt(texts.var.men)
### 5b
# The test statistic for testing whether the variance of ln(texts) is the same for men as it is for women
test.stat.5b = texts.var.men / texts.var.women
# The p-value from that test
p.val.5b = 2*(1-pf(test.stat.5b, df1 = texts.n.men - 1, df2 = texts.n.women - 1))
### 5c
# The t-statistic for whether men and women send a different mean of ln(texts).
pooledvar = (((texts.n.men - 1) * texts.var.men) + ((texts.n.women - 1) * texts.var.women)) / (texts.n.men + texts.n.women -2)
t.stat.5c = (texts.mean.men-texts.mean.women) / sqrt(pooledvar * ((1/texts.n.men)+(1/texts.n.women)))
# The p-value for that test
# us the smaller of the sample sizes (lecture)
p.val.5c = 2*pt(t.stat.5c, df = (texts.n.men + texts.n.women-2))
### 5d
# Output from the t.test command forwhether men and women send a different mean of ln(texts).
t.test.5d = t.test(logwomen, logmen, paired = FALSE, alternative = "two.sided", conf.level = 0.95)
### 5e
# Output from a linear model that predicts 'ln(texts)' using 'female'
texts.lm = lm(log(texts.dat$texts) ~ texts.dat$female)
test.stat.3d
p.val.3d
t.test.5d
t.test.5d = t.test(logwomen, logmen, var.equal=TRUE, alternative = "two.sided", conf.level = 0.95)
t.test.5d
texts.lm
summary(texts.lm)
###########################
# Stat 111, Problem Set 8 #
###########################
# Instructions:
# Upload to Canvas as your_name.R, replacing your_name with your actual name
# IMPORTANT:
# Note that you should be able to run your code all the way through.
# 1) Run this command to erase all variables you've defined:
#       rm(list = ls())
# 2) Paste all your code into R and run it without any errors
my_name = "Meriton Ibrahimi"
#### Read Data ####
gssconvicted <- read.csv("http://stat111.github.io/gssconvicted.csv", header = T)
texts.dat <- read.csv("http://stat111.github.io/stat111textshw8.csv", header = T)
#### Problem 2 ####
# You can use functions from your old psets here
logistic.loglik = function(par, y, x){
a = (par[1]) + ((par[2])*x)
value = sum( (y*a) -log(1 + exp(a)))
return(value)
}
logistic.score = function(par, y, x){
a = (par[1]) + ((par[2])*x)
value_b0 = sum(y - ((exp(a))/(1+exp(a))) )
value_b1 = sum( (y*x) - ( (x*(exp(a))) / (1 + exp(a)) ) )
return(c(value_b0, value_b1))
}
logistic.fisher = function(par, y, x){
a = (par[1]) + ((par[2])*x)
i11 = sum ( (exp(a)) / ((1 + exp(a))^2) )
i21 = sum ( (x*(exp(a))) / ((1 + exp(a))^2) )
i12 = i21
i22 = sum ( ((x^2)*(exp(a))) / ((1 + exp(a))^2) )
return(matrix(c(i11,i21,i12,i22), nrow=2, ncol=2))
}
### 2a
# Store the result of optim() here
beta.optim = optim(par= c(0,0), fn= logistic.loglik, control= list(fnscale=-1), y=gssconvicted$convicted, x=gssconvicted$foreignborn)
# Store the parameter estimates from optim() here
beta.mle = beta.optim$par
### 2b.
# The estimated probability that a foreign-born individual had a conviction
foreign = 1
p.convict.foreign = (exp(beta.mle[1] + ((beta.mle[2])*foreign))) / (1 + exp(beta.mle[1] + ((beta.mle[2])*foreign)))
# The estimated probability that a US-born individual had a conviction
usborn = 0
p.convict.us = (exp(beta.mle[1] + ((beta.mle[2])*usborn))) / (1 + exp(beta.mle[1] + ((beta.mle[2])*usborn)))
### 2c
# The Wald statistic for testing whether the probability of being convicted of a crime is the same for the 2 groups
var = solve(logistic.fisher(beta.mle, gssconvicted$convicted, gssconvicted$foreignborn))[2,2]
wstat = beta.mle[2]  * solve(var) * beta.mle[2]
wald.stat = wstat[1,1]
# The p-value for that Wald statistic
wald.pval = 1-pchisq(wald.stat, df=1)
### 2d
# If you attempt the extra credit, store the confidence interval here.
delta.method.ci = (p.convict.us - p.convict.foreign) + qnorm(c(.025, .975)) * sqrt(var)
#### Problem 3 ####
### 3c
splitconvicted = split(gssconvicted, gssconvicted$foreignborn)
foreigners = splitconvicted$`1`$convicted
borninus = splitconvicted$`0`$convicted
# The estimated proportion of US-born individuals who have been convicted of a crime
p1.hat = mean(borninus)
# The estimated proportion of foreign-born individuals who have been convicted of a crime
p2.hat = mean(foreigners)
### 3d
# The estimated difference (p1 - p2)
d.hat = p1.hat-p2.hat
# The test statistic for testing H0: D = 0
n1 = length(borninus)
n2 = length(foreigners)
p1.hat.var = (p1.hat*(1-p1.hat))/n1
p2.hat.var = (p2.hat*(1-p2.hat))/n2
phat = mean(gssconvicted$convicted)
p.hat.var = phat*(1-phat)*((1/1521) + (1/217))
test.stat.3d = d.hat/sqrt(p.hat.var)
# The p-value for that test
p.val.3d = 2*(1-pnorm(test.stat.3d))
#### Problem 4 ####
### 4b
# The joint probability of observing all the data under model 1
# This should be an exact (not proportional) probability.
p1.function = function(p1){
return(choose(1521,204)*(p1^204)*((1-p1)^1317))
}
p2.function = function(p2){
return(choose(217,5)*(p2^5)*((1-p2)^212))
}
integrate.p1 = integrate(p1.function, 0, 1)
integrate.p2 = integrate(p2.function, 0, 1)
p.data.model1 = integrate.p1$value*integrate.p2$value
### 4c
# The joint probability of observing all the data under model 2
# This should be an exact (not proportional) probability.
p.function = function(p){
return(choose(1521,204)*choose(217,5)*((p^209)*((1-p)^1529)))
}
integrate.p = integrate(p.function, 0,1)
p.data.model2 = integrate.p$value
### 4c
# The Bayes factor that compares model 1 to model 2
bayes.factor = p.data.model1/p.data.model2
### 4f
p1hat = 204/1521
p2hat = 5/217
logm1 = log(p1.function(p1hat)*p2.function(p2hat))
phat = 209/1738
logm2 = log(p.function(phat))
# The BIC value for model 1
bic.model1 = (-2*logm1) + 2*(log(1738)+log(2*pi))
# The BIC value for model 2
bic.model2 = (-2*logm2) + 1*(log(1738)+log(2*pi))
#### Problem 5 ####
### 5a
# Summary statistics for the 'texts' variable
splittexts= split(texts.dat, texts.dat$female)
women = splittexts$`1`$texts
men = splittexts$`0`$texts
logwomen = log(women)
logmen = log(men)
texts.mean.women = mean(logwomen)
texts.n.women = length(logwomen)
texts.var.women = var(logwomen)
texts.sd.women = sqrt(texts.var.women)
texts.mean.men = mean(logmen)
texts.n.men = length(logmen)
texts.var.men = var(logmen)
texts.sd.men = sqrt(texts.var.men)
### 5b
# The test statistic for testing whether the variance of ln(texts) is the same for men as it is for women
test.stat.5b = texts.var.men / texts.var.women
# The p-value from that test
p.val.5b = 2*(1-pf(test.stat.5b, df1 = texts.n.men - 1, df2 = texts.n.women - 1))
### 5c
# The t-statistic for whether men and women send a different mean of ln(texts).
pooledvar = (((texts.n.men - 1) * texts.var.men) + ((texts.n.women - 1) * texts.var.women)) / (texts.n.men + texts.n.women -2)
t.stat.5c = (texts.mean.men-texts.mean.women) / sqrt(pooledvar * ((1/texts.n.men)+(1/texts.n.women)))
# The p-value for that test
# us the smaller of the sample sizes (lecture)
p.val.5c = 2*pt(t.stat.5c, df = (texts.n.men + texts.n.women-2))
### 5d
# Output from the t.test command forwhether men and women send a different mean of ln(texts).
t.test.5d = t.test(logwomen, logmen, var.equal=TRUE, alternative = "two.sided", conf.level = 0.95)
### 5e
# Output from a linear model that predicts 'ln(texts)' using 'female'
texts.lm = lm(log(texts.dat$texts) ~ texts.dat$female)
